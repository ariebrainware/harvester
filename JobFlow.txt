URLQueueItem {
	origin:      string
	refer:       string
	descendants: []string
	level:       int
}

Web Server Receives Job request
+|-> Creates Job in DB, with Job's URLs
+|-> Validates URLs look valid
+|-> publish URLQueueItem to the queue service (foreman)
|
v
QueueService receives URL queue add
+|-> Pull URLQueueItem off queue
+|-> If URL is crawled already
	+|-> remove from pending list
	+|-> get next queue item
+|-> Else if not known
	+|-> Add URL to known
+|-> publish URLQueueItem to worker queue
|
v
Worker Pulls URLQueueItem from queue
+|-> Request Content for URL
+|-> if mime is not text/html update know table entry for refer+URL
+|-> scrape HTML page for URLS
+|-> for each found URL
	+|-> if URL looks like image insert into know with refer as this page, and remove from URL list
+|-> create URLQueueItem for each descendant with this URL as a refer and original URLQueueItem's origin, increment level
+|-> If URL has descendants add descendants to know table with refer of this URL.
+|-> Update this URL as crawled
+|-> if URLQueueItem has descendants and level <= x
	+|-> insert descendants into pending table for origin
+|-> Remove origin+URL from pending table
+|-> Check if origin has anymore entries in pending table
	+|-> find Jobs with origin not completed, and mark as completed


TODO:
+|-> Add checking if URL already is known, and don't scan it <= done via crawled flag
+|-> add checking to mark jobs as completed
|-> Update SQL table def so URLs are primary keys, or indexes.
-|-> Cleanup/add documentation
	|-> crawler needs to be split into testable units
	+|-> add tests for web server logic, util and getRequestedJobURLs
|-> Write up documentation
	|-> design decisions, shortcomings, possible improvements,
	|-> make sure the architecture and code is clearly documented
|-> Upload to github
|-> publish dock on a online doc page
|-> Setup server running on jasdel w/ 2 instances of each layer.
